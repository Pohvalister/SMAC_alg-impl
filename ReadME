В данном проекте представлена реализация алгоритма поиска оптимальных гиперпараметров для алгоритмов машинного обучения, основанная на методе байесовой оптимизаци, её частном случае - алгоритме SMAC.

Проект был написан на языке Python версии 3.6, для запуска кода требуются библиотеки sklearn, numpy, random, datetime

Общий интерфейc solver_base_for_SMAC.Solver представляет интерфейс для оптимизаторов:
	solver_base_for_SMAC.Random_solver - простой, рандомизированный алгоритм поиска
	solver_SMAC.SMAC_solver - реализация алгоритма SMAC

Оптимизатор на вход получает алгоритм для оптимизации - estimator (требуется наличие метода .fit); пространство гиперпараметров; функцию оценщик эффективности - scorer

Пространство гиперпараметров алгоритм получает в виде списка объектов типа solver_base_for_SMAC.Hyperparameter, имеющий 3 реализациии:
	solver_base_for_SMAC.CategoricalHyperparameter - для категориальных параметров
	solver_base_for_SMAC.UniformIntegerHyperparameter - для равномерного пространства целых чисел
	solver_base_for_SMAC.UniformFloatHyperparameter - для равномерного пространства дробных чисел
Примеры использования представлены функциями solver_base_for_SMAC.decision_tree_params_c() и др. в файле solver_base_for_SMAC

Для функции проверки эффективности (scorer) можно использовать встроенные функции проверки, перечисленные в словаре scoring_variation.SCORERS, или же использовать собственные, имеющие тип callable

Также, используя необязательный параметр time_to_evaluate, можно задать время работы алгоритмов - значение по умолчанию выставлено 30 секунд

Метод оптимизатора .fit имеет параметр args, куда передаются тесты для esimator.fit, на которых и будут испытываться различные экземпляры estimator

Примеры работы кода можно увидеть в файле testing.py, в котором сравниваются предложенные оптимизаторы и оптимизаторов из библиотеки scikit-learn: RandomizedSearchCV и GridSearchCV


